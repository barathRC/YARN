
1) Hadoop V2 provides improvement over V1s MapReduce with YARN Yet Another Resource Negotiator.

2) YARN supports distributed processing frameworks such as MapRed, Impala, Spark, etc.

3) YARN Daemons:-

Resource Manager (RM) - Not alike but similar to JT 
One per cluster
Controls App start-up
Schedules resources on the slave nodes

Node Manager (NM) - Not alike but similar to TT
One per slave node
Starts all orocess for running the App
Manages resources on the slave nodes

Job History Server -
One per cluster
Archival of job log files.

4) RM and Job History tracker resides in NameNode. 
5) In large clusters, The RM and JHT might be assigned a single machine that acts as a support machine with other daemons.
6) NM runs on each slave datanodes.
7) When an App is submitted to the YARN cluster, the RM allocates the containers as per the config mentioned in the submitted app.
   Our app knows how to submit the job to YARN clutser RM using the yarn-site.xml config file (HOSTNAME CONFIG IN IT).
8) RM spins a container in one of the slave DN which has Node Manager in it and asks the NM to start AM.
9) Application master is spun up in one of the Slave Node DN having Node Manager which runs as a JVM process.
10) AM is one per cluster and run in its own container.
11) AM is responsible for requesting additional containers from RM.
12) AM then starts in the same container and runs for the wholelife span of the app/ job.
13) AM registers itself with RM. Sends periodic heartbeats to the RM. AM knows where the data blocks resides in HDFS.
14) Containers allocate CPU and Mem on a slave node. Containers actually run the task.
15) After the containers are allocated at specific DN the AM asks the specific NMs in the DNs to start the tasks (Map tasks) in the same containers 
that was requested.
The num of Map tasks are equal to the num of data splits/ data blocks.
16) Once the MAP tasks are completed the intermediate results are persisted locally. The containers are terminated 
and the resources are released to the RM.
16) The AM then requests for RM to provision containers for Reduce tasks. 
